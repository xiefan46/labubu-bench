[common]
definition = "moe_fp8_block_scale_ds_routing_topk8_ng8_kg4_e32_h7168_i2048"
author = "sglang"

[variants.sglang_v1]
name = "sglang_fp8_blockwise_moe_v1"
description = "V1: torch.cat SwiGLU swap + PyTorch FP8 quant + 1GB workspace."
source_dir = "sglang_v1"
language = "python"
entry_point = "main.py::run"
dependencies = ["sgl_kernel"]
destination_passing_style = false

[variants.sglang_v2]
name = "sglang_fp8_blockwise_moe_v2"
description = "V2: Zero-copy PyTorch SwiGLU + sgl_kernel native FP8 quant + 90KB workspace."
source_dir = "sglang_v2"
language = "python"
entry_point = "main.py::run"
dependencies = ["sgl_kernel"]
destination_passing_style = false

[variants.triton_fused]
name = "triton_fused_moe_v1"
description = "Triton fused MoE: 6 kernel launches with fused scatter, SwiGLU+quant, gather. GEMM via sgl_kernel."
source_dir = "triton_fused"
language = "python"
entry_point = "main.py::run"
dependencies = ["sgl_kernel", "triton"]
destination_passing_style = false

[variants.triton_fused_v2]
name = "triton_fused_moe_v2"
description = "Triton fused MoE v2: same kernels as v1 with module-level buffer pre-allocation to eliminate per-call torch.empty overhead."
source_dir = "triton_fused_v2"
language = "python"
entry_point = "main.py::run"
dependencies = ["sgl_kernel", "triton"]
destination_passing_style = false

[variants.cutedsl]
name = "cutedsl_moe_fp8"
description = "CuTeDSL FP8 MoE pipeline on Blackwell SM100+: Routing → GEMM1 → SwiGLU+Requant → GEMM2 → Finalize"
source_dir = "cutedsl"
language = "python"
entry_point = "main.py::run"
dependencies = ["flashinfer"]

[variants.cutedsl_v2]
name = "cutedsl_moe_fp8_v2"
description = "CuTeDSL FP8 MoE v2: vectorized GEMM wrappers (searchsorted+scatter), ~192 GPU→CPU syncs eliminated. 4.1x faster than v1."
source_dir = "cutedsl_v2"
language = "python"
entry_point = "main.py::run"
dependencies = ["flashinfer"]

[variants.cutedsl_v3]
name = "cutedsl_moe_fp8_v3"
description = "CuTeDSL FP8 MoE v3: flat 2D A/C with 128-aligned m_indptr (aligned with trtllm architecture). Less memory for skewed routing."
source_dir = "cutedsl_v3"
language = "python"
entry_point = "main.py::run"
dependencies = ["flashinfer"]

[variants.cutedsl_v3_2]
name = "cutedsl_moe_fp8_v3_2"
description = "CuTeDSL FP8 MoE v3.2: GEMM1 epilogue directly outputs FP8 + per-128-block scales, eliminating separate BF16->FP8 quantization kernel."
source_dir = "cutedsl_v3_2"
language = "python"
entry_point = "main.py::run"
dependencies = ["flashinfer"]

[variants.flashinfer_moe]
name = "flashinfer_moe"
description = "FlashInfer native trtllm_fp8_block_scale_moe baseline (CUTLASS SM100 kernel)."
source_dir = "flashinfer_moe"
language = "python"
entry_point = "main.py::run"
dependencies = ["flashinfer"]
destination_passing_style = false
